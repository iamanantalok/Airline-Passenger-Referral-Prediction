{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamanantalok/Airline-Passenger-Referral-Prediction/blob/main/Capstone_Project_Airline_Passenger_Referral_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Airline Passenger Referral Prediction**  \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Anant Alok\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Airline Passenger Referral Prediction\" project aims to create a data-driven solution for forecasting passenger referrals in a commercial airline. Referrals are instances where current passengers recommend the airline's services to potential new customers. This project acknowledges the significant influence of word-of-mouth recommendations in the aviation sector and aims to optimize and capitalize on this marketing channel.\n",
        "\n",
        "Key Project Objectives:\n",
        "\n",
        "1. Data Collection and Preparation: The project involves gathering comprehensive historical data related to passenger referrals. This data includes various attributes such as passenger demographics, flight details, referral sources, and referral outcomes. Rigorous data cleaning and transformation processes will be carried out to ensure data quality and suitability for analysis.\n",
        "\n",
        "2. Feature Engineering: The project will focus on creating meaningful features from the collected data. These features will include elements such as referral source types (e.g., social media, in-flight conversations), passenger flight frequency, loyalty status, and geographical variables. These engineered features will serve as the foundational inputs for the predictive model.\n",
        "\n",
        "3. Advanced Model Development: The core of the project is the development of a robust predictive model using advanced machine learning techniques. This model will predict the likelihood of a passenger making a referral based on various features. Different algorithms, including logistic regression, decision trees, random forests, and potentially more advanced methods like gradient boosting and neural networks, will be explored and fine-tuned for optimal performance.\n",
        "\n",
        "4. Model Training and Validation: The dataset will be split into distinct training and validation subsets to facilitate model training. Techniques such as cross-validation will be used to ensure the model's reliability and effectiveness. This iterative process will also help optimize the model's hyperparameters.\n",
        "\n",
        "5. Performance Evaluation: Thorough evaluation of the model's predictive accuracy will be conducted using established metrics such as accuracy, precision, recall, F1-score, and the area under the receiver operating characteristic curve (AUC-ROC). These metrics will provide a comprehensive understanding of the model's strengths and weaknesses.\n",
        "\n",
        "6. Insights and Interpretability: The model's results will be carefully analyzed to extract valuable insights into the main drivers of passenger referrals. This analysis may include an examination of feature importance, shedding light on the key factors influencing successful referrals.\n",
        "\n",
        "7. Integration Strategy: The project will outline a strategic plan for seamlessly integrating the predictive model into the airline's operational systems. The objective is to enable real-time referral predictions, enhancing the passenger experience during booking and post-flight interactions.\n",
        "\n",
        "8. Ongoing Monitoring and Maintenance: A comprehensive monitoring system will be established to continuously track the model's performance. Regular updates and maintenance will be carried out to ensure sustained accuracy, accommodating changes in passenger behavior and evolving market dynamics.\n",
        "\n",
        "9. Ethical Considerations: The project will actively address potential ethical concerns related to passenger privacy, data security, and fair treatment of individuals in predictions. Compliance with legal regulations and industry standards will be of utmost importance.\n",
        "\n",
        "10. Business Implications: The project will assess the expected impact of the referral prediction model on critical business metrics. This includes forecasting increased customer acquisition rates, optimizing marketing campaigns, and ultimately improving overall customer satisfaction.\n",
        "\n",
        "In conclusion, the \"Airline Passenger Referral Prediction\" project aims to utilize data-driven insights to transform the airline's marketing efforts. By accurately predicting passenger referrals and understanding the contributing factors, the project seeks to enable targeted marketing strategies, personalized customer interactions, and improved business outcomes."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is centered around an extensive dataset containing airline reviews from 2006 to 2019, covering various popular airlines globally. The dataset includes multiple-choice and free-text questions, offering a comprehensive view of passenger opinions. It was collected in Spring 2019 and serves as the project's foundation.\n",
        "\n",
        "The primary aim is to develop a predictive model capable of identifying passengers likely to recommend the airline to others. Although passenger referrals significantly impact customer acquisition and loyalty, the airline currently lacks the ability to predict potential advocates. This limitation hampers the strategic utilization of this influential marketing channel.\n",
        "\n",
        "The challenge is to build an accurate predictive model considering diverse passenger attributes and behaviors to forecast referral likelihood. Solving this problem holds the potential to maximize referrals, fostering business growth and customer engagement.\n",
        "\n",
        "In essence, this project offers the airline a crucial opportunity to leverage historical data, advanced modeling, and predictive analytics to transform its marketing strategy. Accurate prediction of passenger referrals can enhance customer acquisition, foster loyalty, and elevate performance in the competitive aviation industry."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.impute import SimpleImputer  # Missing value imputation\n",
        "import scipy.stats as stats  # Hypothesis testing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # Categorical encoding\n",
        "\n",
        "# Libraries for text data preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Import SelectKBest, f_regression for feature selection based on statistical tests\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Import train_test_split for splitting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Libraries for model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Importing model evaluation metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Libraries for cross-validation and hyperparameter tuning\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library to mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "airline_df = pd.read_excel(\"/content/drive/MyDrive/Capstone Project-3- Airline-Passenger-Referral-Prediction/data_airline_reviews.xlsx\")\n"
      ],
      "metadata": {
        "id": "zq-Ysv6l6DWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first five rows of the DataFrame\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last five rows of the DataFrame\n",
        "airline_df.tail()"
      ],
      "metadata": {
        "id": "EX5q-aG96nMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the rows and columns in the airline dataset\n",
        "num_rows, num_cols = airline_df.shape\n",
        "\n",
        "# Print the results\n",
        "print(f\"Airline dataset has {num_rows} rows and {num_cols} columns.\")\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the airline dataset\n",
        "airline_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count duplicate rows in the DataFrame\n",
        "duplicate_count = airline_df.duplicated().sum()\n",
        "\n",
        "# Print the total number of duplicate rows\n",
        "print(\"Total Duplicate Rows in the DataFrame:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate rows from the DataFrame in-place\n",
        "airline_df.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "UAQOUFkC7Lqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to identify columns with missing values\n",
        "def show_missing():\n",
        "    missing = airline_df.columns[airline_df.isnull().any()].tolist()\n",
        "    return missing\n",
        "\n",
        "# Missing data counts\n",
        "print('Missing Data Count')\n",
        "print(airline_df[show_missing()].isnull().sum().sort_values(ascending=False))\n",
        "\n",
        "# Separator for clarity\n",
        "print('--' * 50)\n",
        "\n",
        "# Missing data percentages\n",
        "print('Missing Data Percentage')\n",
        "print(round(airline_df[show_missing()].isnull().sum().sort_values(ascending=False) / len(airline_df) * 100, 5))\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of missing values in each column for airline_df\n",
        "missing_percent = (airline_df.isnull().sum() / len(airline_df)) * 100\n",
        "\n",
        "# Create a color map\n",
        "cmap = plt.get_cmap('viridis')\n",
        "\n",
        "# Normalize missing percentages to [0, 1] for colormap\n",
        "normalized_missing = missing_percent / 100\n",
        "\n",
        "# Create a bar plot with colors indicating missing values percentage\n",
        "plt.figure(figsize=(13, 6))\n",
        "bars = plt.bar(missing_percent.index, missing_percent, color=cmap(normalized_missing))\n",
        "plt.title('Percentage of Missing Values by Column')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Percentage')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add a colorbar to indicate the missing values percentage gradient\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=1))\n",
        "sm._A = []  # An empty array is required for the colorbar to work\n",
        "cbar = plt.colorbar(sm, pad=0.03)\n",
        "cbar.set_label('Missing Values Percentage')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Observations:**\n",
        "\n",
        "**Dataset Size:** The dataset comprises a total of 131,895 entries, or rows.\n",
        "\n",
        "**Data Attributes:** Within the dataset, there are 17 columns, each representing distinct features.\n",
        "\n",
        "**Non-Null Values:** The count of \"Non-Null\" values in each column is noteworthy. This figure indicates the absence of missing data, which is crucial for ensuring the accuracy of our analysis and the performance of any modeling.\n",
        "\n",
        "**Data Types:** The \"Dtype\" column denotes the data types for each feature. Specifically, seven columns are of data type float64, signifying numerical data. Meanwhile, ten columns are of object data type, encompassing both categorical variables and textual information.\n",
        "\n",
        "**Insights from Non-Null Counts:**\n",
        "\n",
        "It's worth noting that some columns contain missing data in the form of NaN values. Notably, \"airline,\" \"overall,\" \"author,\" \"review_date,\" \"customer_review,\" \"aircraft,\" \"traveller_type,\" \"cabin,\" \"route,\" \"date_flown,\" \"seat_comfort,\" \"cabin_service,\" \"food_bev,\" \"entertainment,\" \"ground_service,\" \"value_for_money,\" and \"recommended\" exhibit instances of missing values.\n",
        "\n",
        "**Insights from Data Types:**\n",
        "\n",
        "Among the features, seven are of a numeric data type (float64). These are likely to represent ratings or scores for various aspects of the airline experience.\n",
        "\n",
        "Conversely, ten columns are of object data type, encompassing categorical variables and textual data. Notable examples include \"airline,\" \"author,\" \"review_date,\" \"customer_review,\" \"aircraft,\" \"traveller_type,\" \"cabin,\" \"route,\" \"date_flown,\" and \"recommended.\""
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore each column in airline_df\n",
        "for column in airline_df.columns:\n",
        "    print(f\"Column: {column}\")\n",
        "    print(\"Data Type:\", airline_df[column].dtype)\n",
        "    print(\"Number of Unique Values:\", airline_df[column].nunique())\n",
        "    print(\"Value Counts:\")\n",
        "    print(airline_df[column].value_counts())\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate summary statistics for numerical features in the dataset\n",
        "numerical_summary = airline_df.describe()\n",
        "\n",
        "# Display the summary statistics\n",
        "print(numerical_summary)"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each column in the DataFrame\n",
        "for column in airline_df.select_dtypes(include=['object']).columns:\n",
        "    print(f\"Column: {column}\")\n",
        "    print(\"Number of Unique Values:\", airline_df[column].nunique())\n",
        "    print(\"Value Counts:\")\n",
        "    print(airline_df[column].value_counts())\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "fOotQS7e8WGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a concise description of the features in the dataset:\n",
        "\n",
        "1. **Airline:** The name of the airline operating the flight.\n",
        "\n",
        "2. **Overall:** A numerical rating given by customers, typically ranging from 1 to 10, representing their overall satisfaction with the trip.\n",
        "\n",
        "3. **Author:** The person who authored the trip review.\n",
        "\n",
        "4. **Review Date:** The date on which the review was posted.\n",
        "\n",
        "5. **Customer Review:** A free-text field containing the detailed review provided by customers.\n",
        "\n",
        "6. **Aircraft:** The type or model of the aircraft used for the flight.\n",
        "\n",
        "7. **Traveler Type:** This feature indicates the type of traveler, such as business or leisure.\n",
        "\n",
        "8. **Cabin:** The specific cabin class or section of the airplane in which the passenger traveled.\n",
        "\n",
        "9. **Date Flown:** The date on which the flight took place.\n",
        "\n",
        "10. **Seat Comfort:** A numerical rating, usually on a scale of 1 to 5, representing the comfort level of the seats.\n",
        "\n",
        "11. **Cabin Service:** A numerical rating, typically on a scale of 1 to 5, reflecting the quality of service provided within the cabin.\n",
        "\n",
        "12. **Food and Beverage:** A numerical rating, typically on a scale of 1 to 5, evaluating the quality of food and beverages provided during the flight.\n",
        "\n",
        "13. **Entertainment:** A numerical rating, usually on a scale of 1 to 5, assessing the quality and availability of in-flight entertainment.\n",
        "\n",
        "14. **Ground Service:** A numerical rating, typically on a scale of 1 to 5, evaluating the quality of services provided on the ground, such as check-in and baggage handling.\n",
        "\n",
        "15. **Value for Money:** A numerical rating, typically on a scale of 1 to 5, indicating whether passengers felt they received value for the price paid.\n",
        "\n",
        "16. **Recommended:** A binary feature, possibly used as a target variable, indicating whether the customer would recommend the airline (e.g., 1 for recommended, 0 for not recommended).\n",
        "\n",
        "These features collectively provide valuable insights into customer experiences with different airlines, enabling analysis and assessment of various aspects of the airline industry."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values for each variable (column)\n",
        "for column in airline_df.columns:\n",
        "    unique_values = airline_df[column].unique()\n",
        "    print(f\"Column: {column}\")\n",
        "    print(\"Unique Values:\", unique_values)\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Managing Missing Data in the Dataset**"
      ],
      "metadata": {
        "id": "Ll3nA_2NTMLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to check for missing values in a DataFrame\n",
        "def missing_values_check(df):\n",
        "    # Calculate the percentage of missing values for each column\n",
        "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "\n",
        "    # Create a DataFrame to store column names and their respective missing percentages\n",
        "    missing_values_df = pd.DataFrame({'column_name': df.columns,\n",
        "                                      'percent_missing': percent_missing})\n",
        "\n",
        "    # Sort the DataFrame by the percentage of missing values in descending order\n",
        "    return missing_values_df.sort_values('percent_missing', ascending=False)\n",
        "\n",
        "# Call the missing_values_check function with the airline_df DataFrame\n",
        "missing_values_result = missing_values_check(airline_df)\n",
        "\n",
        "# Print the result, which shows columns with missing values sorted by their percentages\n",
        "print(\"Columns with Missing Values (sorted by percentage of missing values):\")\n",
        "print(missing_values_result)\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'aircraft' feature due to a high percentage of missing values\n",
        "airline_df.drop(columns=['aircraft'], inplace=True)"
      ],
      "metadata": {
        "id": "SGgu4xmLTzH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with null values in the specified categorical features\n",
        "airline_df.dropna(subset=['airline', 'author', 'review_date', 'customer_review', 'cabin', 'traveller_type', 'date_flown', 'route', 'recommended'], inplace=True)\n"
      ],
      "metadata": {
        "id": "rnrVNWpkUDqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to analyze and impute missing values\n",
        "columns_to_analyze = ['overall', 'seat_comfort', 'cabin_service', 'food_bev',\n",
        "                      'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Iterate through each numerical column\n",
        "for column in columns_to_analyze:\n",
        "    # Create a distribution plot for the current column\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=airline_df, x=column, kde=True)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate statistics for imputation\n",
        "    median_value = airline_df[column].median()\n",
        "    mean_value = airline_df[column].mean()\n",
        "    mode_value = airline_df[column].mode()[0]\n",
        "\n",
        "    # Print imputation options for the current column\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Median Imputation: {median_value:.2f}\")\n",
        "    print(f\"Mean Imputation: {mean_value:.2f}\")\n",
        "    print(f\"Mode Imputation: {mode_value:.2f}\")\n",
        "    print(\"=\" * 85)\n"
      ],
      "metadata": {
        "id": "KB-54ySqUQs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We generate distribution plots using `sns.histplot()` for each of the columns under analysis.\n",
        "\n",
        "2. We compute and display the statistics for each imputation method, including the median, mean, and mode.\n",
        "\n",
        "3. Next, we visualize the distribution plots to gain insights into the shape of the data distribution, identifying whether it exhibits skewness, symmetry, or the presence of outliers.\n",
        "\n",
        "4. These statistical measures provide an understanding of the central tendency of the data, aiding us in determining the most appropriate imputation strategy for our analysis."
      ],
      "metadata": {
        "id": "NPGv77d-UfrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to impute missing values\n",
        "columns_to_impute = ['overall', 'seat_comfort', 'cabin_service', 'food_bev',\n",
        "                     'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Impute missing values with the median\n",
        "for column in columns_to_impute:\n",
        "    median_value = airline_df[column].median()  # Calculate median\n",
        "    airline_df[column].fillna(median_value, inplace=True)  # Replace missing values with median\n",
        "\n",
        "# Convert columns to int64 data type\n",
        "for column in columns_to_impute:\n",
        "    airline_df[column] = airline_df[column].astype(int)  # Convert to int64 data type\n"
      ],
      "metadata": {
        "id": "lctEuntRUt21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the DataFrame\n",
        "missing_values = airline_df.isnull().sum()\n",
        "\n",
        "# Print the count of missing values for each column\n",
        "print(\"Missing Values Count:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "5SmJg-5FUz6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Improving Date Handling: Datetime Conversion for 'review_date' and 'date_flown'**"
      ],
      "metadata": {
        "id": "OyWQvcybVBS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_review_date(date_review_values):\n",
        "    fin_date = []\n",
        "    for date in date_review_values:\n",
        "        # Extracting day\n",
        "        day = date.split()[0]\n",
        "        if len(day) == 3:\n",
        "            day = int(day[:1])\n",
        "        else:\n",
        "            day = int(day[:2])\n",
        "\n",
        "        # Extracting month\n",
        "        month = date.split()[1]\n",
        "        month_map = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7,\n",
        "                     'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
        "        month = month_map[month]\n",
        "\n",
        "        # Extracting year\n",
        "        year = date.split()[-1]\n",
        "\n",
        "        # Constructing the date in 'yyyy-mm-dd' format\n",
        "        fin_date.append(f'{year}-{month:02d}-{day:02d}')\n",
        "\n",
        "    # Returning as pandas datetime\n",
        "    return pd.to_datetime(fin_date)\n",
        "\n",
        "# Convert the 'review_date' column to pandas datetime using the handle_review_date function\n",
        "airline_df['review_date'] = handle_review_date(airline_df['review_date'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cdUUfTHtVLEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_date_flown(date_flown_values):\n",
        "    fin_date = []\n",
        "    for date in date_flown_values:\n",
        "        if pd.isna(date):\n",
        "            fin_date.append(np.nan)  # Handle missing values as np.nan\n",
        "        else:\n",
        "            try:\n",
        "                fin_date.append(pd.to_datetime(date))  # Try to convert to datetime\n",
        "            except:\n",
        "                year = date.split()[1]\n",
        "                month = date.split()[0]\n",
        "                month_map = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7,\n",
        "                             'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
        "                fin_date.append(pd.to_datetime(f'{year}-{month_map[month]:02d}-01'))  # Handle other date formats\n",
        "\n",
        "    return fin_date\n",
        "\n",
        "# Convert the 'date_flown' column to pandas datetime using the handle_date_flown function\n",
        "airline_df['date_flown'] = handle_date_flown(airline_df['date_flown'])\n",
        "\n",
        "# Extract the month component and create a new 'month' column\n",
        "airline_df['month'] = airline_df['date_flown'].dt.month\n",
        "\n"
      ],
      "metadata": {
        "id": "rEKqzOGNVbnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Enhancing Data Clarity: Splitting 'Route' into 'Arrival' and 'Departure' Columns**"
      ],
      "metadata": {
        "id": "oWj7UjrMVwYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_route():\n",
        "    final_route = []\n",
        "    for route in airline_df.route.values:\n",
        "        if pd.isna(route):\n",
        "            final_route.append((np.nan, np.nan))  # Handle missing values as (np.nan, np.nan)\n",
        "        else:\n",
        "            to_ind = str(route).find(' to ')\n",
        "            via_idx = str(route).find(' via ')\n",
        "            if via_idx == -1:\n",
        "                final_route.append((str(route)[:to_ind], str(route)[to_ind + 3:]))\n",
        "            else:\n",
        "                final_route.append((str(route)[:to_ind], str(route)[to_ind + 3:via_idx]))\n",
        "    return final_route\n",
        "\n",
        "# Update the 'route' column using the handle_route function\n",
        "airline_df['route'] = handle_route()\n",
        "\n",
        "# Create the 'arrival_city' and 'departure_city' columns from the 'route' column\n",
        "airline_df['arrival_city'] = airline_df['route'].apply(lambda x: x[0])\n",
        "airline_df['departure_city'] = airline_df['route'].apply(lambda x: x[1])\n",
        "\n",
        "# Drop the original 'route' column\n",
        "airline_df.drop('route', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "jrj7K2SjV6fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Initial Data Cleanup:**\n",
        "- To address data quality issues, the 'aircraft' feature, which contained nearly 70% missing values, was removed from the dataset.\n",
        "- The dataset was further prepared by categorizing features into two groups: categorical and numerical variables.\n",
        "- The 'date_flown' and 'review_date' columns, originally stored as object data types, were converted into Pandas DateTime objects to facilitate more effective exploratory data analysis (EDA).\n",
        "- For improved data organization and analysis, the 'route' feature was split into two separate features: 'arrival_city' and 'departure_city,' and the 'route' feature itself was subsequently dropped.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exploring the Distributions of Numeric Features**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x3 grid of subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
        "\n",
        "# Distribution of Overall Ratings\n",
        "sns.histplot(data=airline_df, x='overall', bins=10, kde=True, ax=axes[0, 0])\n",
        "axes[0, 0].set_xlabel('Overall Rating')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Distribution of Overall Ratings')\n",
        "\n",
        "# Distribution of Seat Comfort Ratings\n",
        "sns.histplot(data=airline_df, x='seat_comfort', bins=5, kde=True, ax=axes[0, 1])\n",
        "axes[0, 1].set_xlabel('Seat Comfort Rating')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('Distribution of Seat Comfort Ratings')\n",
        "\n",
        "# Distribution of Cabin Service Ratings\n",
        "sns.histplot(data=airline_df, x='cabin_service', bins=5, kde=True, ax=axes[0, 2])\n",
        "axes[0, 2].set_xlabel('Cabin Service Rating')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "axes[0, 2].set_title('Distribution of Cabin Service Ratings')\n",
        "\n",
        "# Distribution of Food and Beverage Ratings\n",
        "sns.histplot(data=airline_df, x='food_bev', bins=5, kde=True, ax=axes[1, 0])\n",
        "axes[1, 0].set_xlabel('Food and Beverage Rating')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Distribution of Food and Beverage Ratings')\n",
        "\n",
        "# Distribution of Entertainment Ratings\n",
        "sns.histplot(data=airline_df, x='entertainment', bins=5, kde=True, ax=axes[1, 1])\n",
        "axes[1, 1].set_xlabel('Entertainment Rating')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Distribution of Entertainment Ratings')\n",
        "\n",
        "# Distribution of Ground Service Ratings\n",
        "sns.histplot(data=airline_df, x='ground_service', bins=5, kde=True, ax=axes[1, 2])\n",
        "axes[1, 2].set_xlabel('Ground Service Rating')\n",
        "axes[1, 2].set_ylabel('Frequency')\n",
        "axes[1, 2].set_title('Distribution of Ground Service Ratings')\n",
        "\n",
        "# Customize the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a countplot for the distribution of Value for Money Ratings\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data=airline_df, x='value_for_money', bins=6, kde=True)\n",
        "plt.xlabel('Value for Money Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Value for Money Ratings')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_zL3KpwcFLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histplot function, when used with kde (Kernel Density Estimation), is particularly well-suited for analyzing continuous numerical data. This function combines the traditional histogram (bar plot) with a smoothed density curve, allowing it to provide an estimate of the underlying data distribution. It serves as a valuable tool for visualizing the characteristics of continuous distributions, aiding in the identification of features like peaks and valleys within the data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ratings of 1 to 2 are the most common in the overall feature.\n",
        "2. Regarding Seat Comfort, it's notable that the highest rating is 1, followed by a second-highest rating of 4.\n",
        "3. For the Cabin Service feature, the highest rating is 5, and the second-highest rating is 1.\n",
        "4. In the Food and Beverage feature, ratings of 2, 4, and 5 occur with roughly equal frequency.\n",
        "5. Both the Entertainment and Ground Service features show that the highest rating is 3, with the second-highest rating being 1.\n",
        "6. The Value for Money feature indicates that most passengers assign a rating of 1 as the highest, suggesting that many airlines may not provide satisfactory service to their passengers.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the insights we've gathered point to opportunities for enhancement and the potential for positive business outcomes through the resolution of specific issues that lead to lower ratings. Improving seat comfort, enriching food and beverage choices, and delivering better value for money can positively impact passenger satisfaction and foster loyalty.\n",
        "\n",
        "Conversely, there's a possibility of negative growth stemming from the frequent occurrence of low ratings in the overall experience, seat comfort, and value for money. These aspects play a critical role in passenger satisfaction and could result in unfavorable reviews, reduced repeat business, and damage to the airline's reputation if left unattended."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ranking Airlines by Trip Frequency: Top 10 Airlines**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 10 airlines based on the frequency of trips\n",
        "top_10_airlines = airline_df['airline'].value_counts().head(10)\n",
        "\n",
        "# Create a bar plot for the top 10 airlines by count\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_10_airlines.values, y=top_10_airlines.index, palette='viridis')\n",
        "plt.xlabel('Number of Trips')\n",
        "plt.ylabel('Airline')\n",
        "plt.title('Top 10 Airlines by Number of Trips')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selection of a bar plot for this visualization is appropriate as it efficiently illustrates the distribution of reviews among different airlines, facilitating a straightforward comparison of the top 10 airlines. This choice capitalizes on the advantages of bar plots in presenting categorical data and enabling meaningful side-by-side comparisons."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. American Airlines stands out as the most widely recognized and frequented airline, boasting the highest number of reviews. This suggests a strong reputation and passenger trust in this airline.\n",
        "\n",
        "2. Spirit Airlines, despite having fewer reviews than American Airlines, secures the second spot in popularity. This implies that it is a preferred choice among budget-conscious travelers seeking economical options.\n",
        "\n",
        "3. United Airlines and British Airways also enjoy significant popularity, attributed to their extensive range of destinations and services catering to diverse traveler needs.\n",
        "\n",
        "4. Airlines like China Southern Airlines, Emirates, Delta Air Lines, and Turkish Airlines have earned popularity within specific regions of the world. For instance, China Southern Airlines is favored for travel to and from China, while Emirates serves as a preferred option for Middle East-bound travelers.\n",
        "\n",
        "5. Frontier Airlines and Qatar Airways operate as low-cost carriers, offering competitive fares but potentially differing in the level of service they provide when compared to other airlines."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights can have a positive business impact for airlines by helping them:\n",
        "\n",
        "1. Improve customer service, addressing specific areas of concern like food quality.\n",
        "2. Target marketing campaigns effectively based on customer preferences, such as budget-conscious travelers.\n",
        "3. Develop new products and services tailored to customer needs, like offering more legroom.\n",
        "\n",
        "These insights also prevent negative growth by addressing issues such as uncomfortable seats, food dissatisfaction, and poor customer service. Addressing these concerns enhances customer satisfaction and loyalty, ultimately benefiting the airline's bottom line."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Understanding Categorical Data Distribution**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Traveller Types\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='traveller_type', palette='Set2')\n",
        "plt.xlabel('Traveller Type')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Traveller Types')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Cabin Types\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='cabin', palette='Set3')\n",
        "plt.xlabel('Cabin Type')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Cabin Types')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Recommended\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='recommended', palette='Pastel1')\n",
        "plt.xlabel('Recommended')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Recommended')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is an effective choice for visualizing categorical data distributions. It is frequently employed when the goal is to grasp the frequency distribution of distinct categories or levels within a variable. This type of plot offers valuable insights into the composition and distribution of specific features, making it a valuable tool for univariate analyses of this nature."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. \"Solo Leisure\" is the most frequent traveler type, suggesting that a substantial portion of passengers in the dataset travel independently.\n",
        "2. \"Economy Class\" stands out as the predominant cabin type, with a notably higher frequency compared to other cabin types.\n",
        "3. A greater number of passengers opted for a \"no\" recommendation than a \"yes,\" implying that a significant portion of passengers did not have a positive enough experience to endorse the airline."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights can positively impact airlines by tailoring their services to customer needs, enhancing satisfaction, loyalty, and revenue. For instance, focusing on Economy Class improvements, addressing customer concerns, and boosting customer service can drive growth.\n",
        "\n",
        "However, some insights indicate potential negative growth. A rising number of non-recommendations suggests unmet expectations, potentially lowering satisfaction and loyalty. Declining Business Class passengers may signify price sensitivity among business travelers, impacting revenue.\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Number of Travelers per Cabin Class**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the color palette\n",
        "sns.set_palette('gist_ncar')\n",
        "\n",
        "# Count the number of passengers in each cabin class and create a pie chart\n",
        "airline_df['cabin'].value_counts().plot(kind='pie', autopct='%1.0f%%', figsize=(10, 5))\n",
        "\n",
        "# Add a title\n",
        "plt.title('Distribution of Passengers by Cabin Class')\n",
        "\n",
        "# Display the pie chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart offers a valuable snapshot of airline passenger demographics, highlighting the popularity of different travel classes. Economy class leads the preferences, followed by premium economy, business class, and first class. This data can guide airlines in pricing and service-related decision-making."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart displays a pie chart illustrating the distribution of passengers across different airline classes. It reveals that 79% of passengers opt for economy class, while first class accounts for a modest 3%. Premium economy represents 4% of passengers, and business class comprises 15%.\n",
        "\n",
        "This pie chart provides insightful demographic information about airline passengers. It underscores that the majority of travelers choose economy class, likely due to its affordability. In contrast, the higher costs associated with first class and business class restrict their appeal to a smaller segment of passengers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights can positively impact airlines in several ways:\n",
        "\n",
        "1. **Economy Class Focus:** Given the majority of passengers travel in economy class, airlines can enhance marketing and services for this segment, including discounts, comfort improvements, and better in-flight entertainment.\n",
        "\n",
        "2. **Expand Premium Economy:** With a rising share of passengers in premium economy, airlines can consider expanding offerings, such as more seats and enhanced amenities.\n",
        "\n",
        "3. **Target Business Travelers:** Airlines can cater to the valuable business traveler segment by offering discounts, comfortable seats, and business-oriented amenities like Wi-Fi and workspaces.\n",
        "\n",
        "However, if not managed carefully, these insights could also lead to negative growth. Overemphasizing economy class may alienate high-paying customers, and excessive price increases could deter budget-conscious travelers."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Passenger Travel Patterns by Month**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot for the distribution of travel months\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=airline_df, x='month', palette='PuBuGn')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.title('Distribution of Passengers Travel by Month')\n",
        "plt.xticks(ticks=range(0, 12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'month' feature falls under the category of categorical data, given that it comprises distinct and discrete categories representing months of the year. Bar plots serve as a powerful tool for visualizing the distribution of such categorical data. In this context, our goal is to ascertain the frequency of passenger travel for each month. Bar plots excel in presenting the count of occurrences for each category (i.e., month) in a straightforward and easily interpretable manner."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. July emerges as the top choice for travel, boasting 3,410 passengers. This popularity is likely attributed to July being a summer month, a prime season for vacations.\n",
        "2. August follows closely as the second most favored travel month, with 3,321 passengers, also benefiting from the summer season.\n",
        "3. June, December, and September are also prominent travel months, hosting 3,237, 3,202, and 3,014 passengers, respectively. These months, situated in summer or fall, typically offer favorable travel weather.\n",
        "4. Conversely, January, February, and March see the lowest travel numbers, with 2,965, 2,403, and 2,494 passengers, respectively. These winter months, marked by cold and snowy weather, tend to discourage travel.\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gained insights from the chart can positively impact airlines and travel agencies in several ways:\n",
        "\n",
        "1. **Strategic Planning:** Airlines can tailor marketing and pricing strategies to capitalize on peak travel months, optimizing revenue.\n",
        "2. **Destination Planning:** Travel agencies can design itineraries around popular destinations during peak months, driving sales.\n",
        "\n",
        "3. **Promotions:** Special offers and discounts can be crafted to boost travel demand during less popular months.\n",
        "\n",
        "However, these insights can also have negative implications:\n",
        "\n",
        "1. **Overbooking Risk:** Airlines might overbook flights during peak months, risking customer dissatisfaction.\n",
        "2. **Service Reliability:** Travel agencies may face challenges if they oversell travel packages, leading to cancellations and refunds.\n",
        "3. **Adaptation Delays:** Slow response to changing travel demand can result in missed revenue opportunities.\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Passenger Counts by Review Date and Date Flown**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Distribution of passengers by review year\n",
        "plt.subplot(1, 2, 1)\n",
        "airline_df.groupby(airline_df.review_date.dt.year)['review_date'].count().plot(\n",
        "    ylabel='Number of Passengers',\n",
        "    xticks=range(2015, 2019)\n",
        ")\n",
        "plt.title('Distribution of Passengers by Review Year')\n",
        "\n",
        "# Subplot 2: Distribution of passengers by travel year\n",
        "plt.subplot(1, 2, 2)\n",
        "airline_df.groupby(airline_df.date_flown.dt.year)['date_flown'].count().plot(\n",
        "    ylabel='Number of Passengers',\n",
        "    xticks=range(2013, 2019)\n",
        ")\n",
        "plt.title('Distribution of Passengers by Travel Year')\n",
        "\n",
        "# Adjust layout and display the subplots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot layout enables a simultaneous comparison of passenger counts across multiple years for both review dates and date flown. This facilitates the identification of patterns, distinctions, and trends between these two perspectives, offering a comprehensive view of passenger distribution over time."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Over time, there has been a noticeable increase in both passenger counts and the number of reviews. This growth can be attributed to various factors, including the rising popularity of air travel and the widespread availability of online review platforms.\n",
        "\n",
        "2. Interestingly, the number of reviews consistently exceeds the number of passengers, indicating that a significant proportion of passengers actively engage in providing feedback after their flights.\n",
        "\n",
        "3. A peak in both passenger counts and reviews occurs in 2018, likely influenced by the record-breaking year in air travel.\n",
        "\n",
        "4. Conversely, there is a decline in both passenger counts and reviews in 2019, possibly due to factors like a global economic slowdown and the emergence of budget airlines."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Impact:**\n",
        "\n",
        "1. **Improved Customer Service:** The airline can enhance customer service by addressing complaints promptly, efficiently resolving issues, and providing superior support.\n",
        "\n",
        "2. **Attracting More Passengers:** Strategies like competitive pricing, improved in-flight entertainment, and new routes can help the airline draw more passengers.\n",
        "\n",
        "3. **Industry Trends:** The insights can assist the airline in staying ahead of industry trends, enabling informed decisions and maintaining a competitive edge.\n",
        "\n",
        "**Negative Impact:**\n",
        "\n",
        "1. **Market Share Loss:** Failure to address factors contributing to declining passengers and reviews could result in continued market share erosion.\n",
        "\n",
        "2. **Reputation Damage:** Ill-received business changes may lead to customer loss and harm the airline's reputation."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exploring the Relationship Between Overall and Sub-Ratings**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the color palette\n",
        "sns.set_palette('crest')\n",
        "\n",
        "# List of different kinds of ratings columns (excluding 'overall')\n",
        "review_columns = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(review_columns), ncols=1, figsize=(10, 6 * len(review_columns)))\n",
        "\n",
        "# Loop through each review column and create a bar plot\n",
        "for i, col in enumerate(review_columns):\n",
        "    ax = axes[i]\n",
        "    x = airline_df.groupby('overall')[col].value_counts().unstack()\n",
        "    x.plot(kind='bar', ax=ax)\n",
        "    ax.set_title(f'Relationship between {col.replace(\"_\", \" \").title()} and Overall Ratings')\n",
        "    ax.set_xlabel('Overall Rating')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.legend(title=col.replace(\"_\", \" \").title(), loc='upper left')\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are well-suited for comparing categorical data, where each category corresponds to a bar. They facilitate straightforward comparisons of category distributions across various groups, such as different 'overall' ratings."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ratings for seat_comfort, cabin_service, and food_bev exhibit an upward trend as the overall rating increases. This suggests that passengers tend to be more content with these aspects when they assign a higher overall rating to the airline. On the other hand, the ratings for entertainment, ground_service, and value_for_money also show an increase with the overall rating, though the correlation is somewhat weaker. This implies that while these factors remain significant for passengers, they may not carry as much weight as seat_comfort, cabin_service, and food_bev in determining the overall rating."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Impact:**\n",
        "\n",
        "The insights gained can positively impact airlines in several ways:\n",
        "\n",
        "1. **Enhanced Seat Comfort:** Investment in more spacious and comfortable seats.\n",
        "2. **Improved Cabin Service:** Recruitment of experienced and friendly flight attendants.\n",
        "3. **Enhanced Food and Beverage Offerings:** Partnerships with renowned chefs and diversified menus.\n",
        "4. **Upgraded Entertainment:** Installation of larger screens and expanded channel offerings.\n",
        "5. **Efficient Ground Service:** Faster check-in and baggage handling.\n",
        "6. **Better Value for Money:** Competitive pricing and more affordable fares.\n",
        "\n",
        "**Slower Growth:**\n",
        "\n",
        "While no insights directly lead to negative growth, some could result in a slower growth rate if unaddressed. For instance, neglecting seat comfort, cabin service, or dining options may prompt passengers to opt for competitors offering superior services, potentially hindering growth."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Understanding the Interplay of Overall Ratings, Traveler Types, and Cabin Choices**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the color palette\n",
        "sns.set_palette('crest')\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 18))\n",
        "\n",
        "# List of categorical features to compare with 'overall'\n",
        "categorical_features = ['traveller_type', 'cabin']\n",
        "\n",
        "# Loop through each categorical feature and create a grouped bar plot\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    ax = axes[i]\n",
        "    sns.countplot(data=airline_df, x=feature, hue='overall', ax=ax)\n",
        "    ax.set_title(f'Comparison of Overall Ratings by {feature.replace(\"_\", \" \").title()}')\n",
        "    ax.set_xlabel(feature.replace(\"_\", \" \").title())\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.legend(title='Overall Rating')\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The grouped bar plot is an effective choice for visually representing and comparing the distribution of 'overall' ratings across various categories within categorical features. It offers a clear and informative method for examining the relationship between these variables and uncovering possible patterns or trends."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Solo leisure travelers exhibit the highest average overall rating at 5.08, surpassing business travelers (4.44), couple leisure travelers (4.36), and family leisure travelers (4.32). This implies that solo leisure travelers tend to have a more contented overall experience with airlines compared to other traveler types.\n",
        "\n",
        "2. Business class attains the highest average overall rating at 6.41, signifying a significant lead over economy class (4.22), first class (6.09), and premium economy (5.17). This indicates that passengers express notably higher satisfaction with their overall experience in business class compared to other cabin classes."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Traveller Type:**\n",
        "\n",
        "- **Solo Leisure Travelers:** Airlines can enhance service for solo leisure travelers with personalized amenities like priority check-in, free Wi-Fi, and power outlets.\n",
        "\n",
        "- **Business Travelers:** Airlines can cater to business travelers with flexible ticket policies, premium amenities like lie-flat seats, and access to airport lounges.\n",
        "\n",
        "**Cabin Type:**\n",
        "\n",
        "- **Economy Class:** Improving space and comfort for economy class passengers by offering more legroom and wider aisles.\n",
        "\n",
        "- **Economy Class Amenities:** Enhancing the in-flight experience for economy class passengers with complimentary food and drinks, Wi-Fi, and entertainment options.\n",
        "\n",
        "These suggestions provide specific actions airlines can take to address passenger preferences and improve their overall experience."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Recommended Feature Dynamics: Airlines, Traveler Types, and Cabins**\n"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'airline' and 'recommended', count occurrences, and create a bar plot\n",
        "airline_count = airline_df.groupby(['airline', 'recommended']).agg({'recommended': 'count'}).rename(columns={'recommended': 'count'}).sort_values(by='count', ascending=False).unstack()\n",
        "airline_count[:20].plot(kind='bar', figsize=(10, 5))\n",
        "plt.legend(['No', 'Yes'])\n",
        "plt.xlabel('Airline')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Recommended vs. Airline')\n",
        "plt.show()\n",
        "\n",
        "# Group by 'traveller_type' and 'recommended', count occurrences, and create a bar plot\n",
        "traveller_count = airline_df.groupby(['traveller_type', 'recommended']).agg({'recommended': 'count'}).rename(columns={'recommended': 'count'}).sort_values(by='count', ascending=False).unstack()\n",
        "traveller_count[:4].plot(kind='bar', figsize=(10, 5))\n",
        "plt.legend(['No', 'Yes'])\n",
        "plt.xlabel('Traveller Type')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Recommended vs. Traveller Type')\n",
        "plt.show()\n",
        "\n",
        "# Group by 'cabin' and 'recommended', count occurrences, and create a bar plot\n",
        "cabin_count = airline_df.groupby(['cabin', 'recommended']).agg({'recommended': 'count'}).rename(columns={'recommended': 'count'}).sort_values(by='count', ascending=False).unstack()\n",
        "cabin_count[:4].plot(kind='bar', figsize=(10, 5))\n",
        "plt.legend(['No', 'Yes'])\n",
        "plt.xlabel('Cabin')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Recommended vs. Cabin')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots offer a straightforward and interpretable way to visualize data. In a bar plot, each bar represents the count of passengers who have recommended a particular airline. The height of each bar corresponds to the number of passengers who recommended that airline, making it easy to discern which airlines received more recommendations."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Recommended vs. Airline:**\n",
        "\n",
        "- Airlines like ANA All Nippon Airways, Aegean Airlines, and Air New Zealand receive predominantly 'yes' (recommended) responses, indicating positive passenger sentiment.\n",
        "- Airlines such as Adria Airways, Air Arabia, and Alaska Airlines have a higher count of 'no' (not recommended), suggesting areas for improvement in passenger recommendations.\n",
        "\n",
        "**Recommended vs. Traveler Type:**\n",
        "\n",
        "- Business travelers ('Business') tend to provide more 'yes' recommendations, reflecting a positive sentiment.\n",
        "- Couples ('Couple Leisure') and solo travelers ('Solo Leisure') exhibit a relatively balanced distribution of 'yes' and 'no' recommendations.\n",
        "\n",
        "**Recommended vs. Cabin:**\n",
        "\n",
        "- 'Economy Class' passengers have diverse experiences and preferences, resulting in a mixed distribution of 'yes' and 'no' recommendations.\n",
        "- 'Business Class' passengers receive a higher count of 'yes' recommendations, indicating positive reception.\n",
        "- 'First Class' and 'Premium Economy' passengers also have a balanced distribution of 'yes' and 'no' recommendations."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "- **Enhanced Passenger Experience:** Airlines with more 'yes' recommendations can expect increased customer loyalty, positive word-of-mouth, and a strong brand reputation, ultimately attracting new customers and fostering repeat business.\n",
        "\n",
        "- **Focus on Business Travelers:** Business travelers tend to provide more positive recommendations, offering airlines an opportunity to tailor services and amenities to this segment, potentially boosting bookings and loyalty.\n",
        "\n",
        "- **Premium Cabin Services:** 'Business Class' and 'First Class' passengers receive more 'yes' recommendations, allowing airlines to enhance premium cabin services, attract luxury-seeking travelers, and justify higher fares.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "- **Areas of Improvement:** Airlines with a higher count of 'no' recommendations may face negative growth unless they address the underlying issues causing dissatisfaction, which can result in reduced customer satisfaction, negative reviews, and decreased repeat business.\n",
        "\n",
        "- **Economy Class Challenges:** The mixed distribution of 'yes' and 'no' recommendations among 'Economy Class' passengers highlights the need to address comfort, service quality, and amenities in this class to prevent decreased customer loyalty and retention."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Passenger Ratings Across Traveler Types and Cabins**"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the color palette\n",
        "sns.set_palette('Set2')\n",
        "\n",
        "# List of different kinds of ratings columns\n",
        "rating_columns = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(rating_columns), ncols=2, figsize=(15, 6 * len(rating_columns)))\n",
        "\n",
        "# Loop through each rating column and create bar plots for 'traveller_type' and 'cabin'\n",
        "for i, col in enumerate(rating_columns):\n",
        "    ax1 = axes[i, 0]\n",
        "    ax2 = axes[i, 1]\n",
        "\n",
        "    # Bar plot for 'traveller_type'\n",
        "    sns.barplot(data=airline_df, x='traveller_type', y=col, hue=airline_df['recommended'], ax=ax1)\n",
        "    ax1.set_title(f'{col.replace(\"_\", \" \").title()} by Traveller Type')\n",
        "    ax1.set_xlabel('Traveller Type')\n",
        "    ax1.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Box plot for 'cabin'\n",
        "    sns.boxplot(data=airline_df, x='cabin', y=col, hue=airline_df['recommended'], palette=['blue', 'yellow'], ax=ax2)\n",
        "    ax2.set_title(f'{col.replace(\"_\", \" \").title()} by Cabin')\n",
        "    ax2.set_xlabel('Cabin')\n",
        "    ax2.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting this particular plot enables us to effectively communicate how various facets of the air travel experience are interpreted by distinct passenger segments. This, in turn, empowers airlines to make well-informed decisions to enhance and optimize their services."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Seat Comfort:**\n",
        "\n",
        "- Business travelers tend to rate seat comfort higher compared to other traveler types.\n",
        "- First Class passengers generally rate seat comfort higher compared to other cabin types.\n",
        "\n",
        "**Cabin Service:**\n",
        "\n",
        "- Business travelers rate cabin service higher on average.\n",
        "- Passengers in Business Class cabins tend to rate cabin service higher compared to other cabin types.\n",
        "\n",
        "**Food and Beverage:**\n",
        "\n",
        "- Solo travelers tend to rate food and beverage quality higher on average.\n",
        "- Passengers in Business Class cabins rate food and beverage quality higher compared to other cabin types.\n",
        "\n",
        "**Entertainment:**\n",
        "\n",
        "- Business travelers tend to rate entertainment higher on average.\n",
        "- Passengers in Business Class and First Class cabins generally rate entertainment higher compared to other cabin types.\n",
        "\n",
        "**Ground Service:**\n",
        "\n",
        "- Business travelers rate ground service higher on average.\n",
        "- Passengers in Business Class cabins tend to rate ground service higher compared to other cabin types.\n",
        "\n",
        "**Value for Money:**\n",
        "\n",
        "- Solo travelers tend to rate value for money higher on average.\n",
        "- Passengers in Business Class cabins rate value for money higher compared to other cabin types.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Understanding passenger preferences helps airlines enhance the aspects passengers value most, leading to increased customer satisfaction, loyalty, and repeat business. For example:\n",
        "\n",
        "1. Improving seat comfort in economy class with wider seats and more legroom.\n",
        "2. Enhancing cabin service with personalized attention from well-trained flight attendants.\n",
        "3. Elevating food and beverage quality with chef-prepared meals on chinaware.\n",
        "4. Expanding entertainment options with more channels and movies.\n",
        "5. Enhancing ground service with dedicated check-in counters and lounges.\n",
        "\n",
        "**Negative Growth Insights:**\n",
        "\n",
        "Some insights could lead to negative growth if not addressed. For instance, the higher value-for-money rating in business class compared to economy class suggests potential overpricing in economy. Airlines risk losing customers to budget carriers offering lower fares if this issue isn't addressed."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Impact of Flight Month and Years on Passenger Ratings**"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year and month from review_date\n",
        "airline_df['flight_year'] = airline_df['review_date'].dt.year\n",
        "airline_df['flight_month'] = airline_df['review_date'].dt.month\n",
        "\n",
        "# List of different kinds of ratings columns\n",
        "rating_columns = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(rating_columns), ncols=2, figsize=(15, 6 * len(rating_columns)))\n",
        "\n",
        "# Loop through each rating column and create line plots for flight year and month\n",
        "for i, col in enumerate(rating_columns):\n",
        "    ax1 = axes[i, 0]\n",
        "    ax2 = axes[i, 1]\n",
        "\n",
        "    # Line plot for flight year\n",
        "    sns.lineplot(data=airline_df, x='flight_year', y=col, ax=ax1)\n",
        "    ax1.set_title(f'{col.replace(\"_\", \" \").title()} by Flight Year')\n",
        "    ax1.set_xlabel('Flight Year')\n",
        "    ax1.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Line plot for flight month\n",
        "    sns.lineplot(data=airline_df, x='flight_month', y=col, ax=ax2)\n",
        "    ax2.set_title(f'{col.replace(\"_\", \" \").title()} by Flight Month')\n",
        "    ax2.set_xlabel('Flight Month')\n",
        "    ax2.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax2.set_xticks(range(1, 13))\n",
        "    ax2.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plots are a standard choice for visualizing temporal trends or variations in data. In this context, we aim to explore how passenger ratings have evolved across various flight years and months. Line plots provide a clear means of observing any patterns or shifts in ratings as we examine changes in the time variable, whether it's the year or the month."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact of Flight Year on Ratings:**\n",
        "\n",
        "- Overall ratings declined steadily from 2015 to 2019.\n",
        "- Seat comfort, cabin service, food and beverage, entertainment, and ground service ratings followed a similar decreasing trend over the years.\n",
        "- Value for money ratings initially dropped (2015-2016) but then began a slight recovery.\n",
        "\n",
        "**Impact of Flight Month on Ratings:**\n",
        "\n",
        "- Overall ratings remained relatively stable throughout the year, with a slight upswing during the middle months.\n",
        "- Ratings for seat comfort, cabin service, food and beverage, and entertainment displayed similar patterns with minor fluctuations.\n",
        "- Ground service and value for money ratings also showed consistent patterns with slight variations."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "- **Continuous Improvement:** Increasing overall and specific ratings over the years indicate improved services and passenger experiences, fostering loyalty and attracting more passengers.\n",
        "\n",
        "- **Seasonal Adaptation:** Recognizing seasonal rating patterns enables the airline to adjust services during peak travel times, addressing specific issues.\n",
        "\n",
        "**Areas for Improvement:**\n",
        "\n",
        "- **Declining Ratings:** Persistent rating declines pose potential issues, including reduced satisfaction and customer attrition, necessitating corrective action.\n",
        "\n",
        "- **Monthly Inconsistencies:** Fluctuations in monthly ratings highlight service quality inconsistencies, warranting investigation and improvement.\n",
        "\n",
        "- **Competitor Comparison:** Contrasting ratings with competitors helps identify areas of deficiency, prompting efforts to bridge gaps in service quality."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Analyzing the Impact of Overall Ratings on Passenger Recommendations**"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean overall rating for recommended and not recommended reviews\n",
        "mean_rating_recommended = airline_df[airline_df['recommended'] == 'yes']['overall'].mean()\n",
        "mean_rating_not_recommended = airline_df[airline_df['recommended'] == 'no']['overall'].mean()\n",
        "\n",
        "# Create data for the donut chart\n",
        "labels = ['Recommended', 'Not Recommended']\n",
        "sizes = [mean_rating_recommended, mean_rating_not_recommended]\n",
        "colors = ['#66b3ff','#99ff99']\n",
        "explode = (0.1, 0)  # explode the 1st slice (Recommended)\n",
        "\n",
        "# Create a donut chart\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%.1f%%', startangle=90, pctdistance=0.85, explode=explode)\n",
        "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "\n",
        "# Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.tight_layout()\n",
        "plt.title('Mean Overall Rating for Recommended vs. Not Recommended Reviews')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected the donut chart for this visualization due to its ability to effectively depict the distribution of mean overall ratings between recommended and not recommended reviews. The donut chart enables a visual comparison between these two categories while also indicating the proportion of each category relative to the whole. The use of distinctive colors and the presence of the center circle serve to highlight the contrast between the two categories and offer a clear and concise visual representation of the data."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight gleaned from the donut chart reveals a distinct contrast in the mean overall ratings between recommended and not recommended reviews. The mean overall rating for recommended reviews is notably higher in comparison to the mean overall rating for not recommended reviews. This observation suggests that reviews marked as recommended generally exhibit significantly higher overall ratings, indicative of a positive sentiment, whereas not recommended reviews tend to display considerably lower ratings, signifying a negative sentiment."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The significant difference in mean overall ratings between recommended and not recommended reviews indicates that positive customer sentiment and recommendations are correlated with higher overall ratings. This insight can be leveraged by the airline to focus on improving customer satisfaction, addressing issues highlighted in not recommended reviews, and enhancing the overall travel experience. By doing so, the airline can aim to increase the number of positive reviews and recommendations, which can attract more customers and foster loyalty."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Correlation Heatmap**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "variables = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(airline_df[variables].corr(), annot=True)\n",
        "plt.title('Correlation Heatmap')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap proves to be a valuable tool for swiftly pinpointing patterns of correlation among numerical features within the dataset. It serves to elucidate which features exhibit a more robust association with one another, offering insights that can guide subsequent analysis or modeling endeavors."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strong Positive Correlations:**\n",
        "- Overall ratings are strongly positively correlated with seat comfort, cabin service, ground service, and value for money ratings.\n",
        "\n",
        "**Moderate to Strong Positive Correlations:**\n",
        "- Seat comfort, cabin service, and value for money ratings show strong positive correlations.\n",
        "\n",
        "**Moderate Positive Correlations:**\n",
        "- Food and beverage ratings are moderately positively correlated with cabin service and entertainment ratings.\n",
        "\n",
        "**Moderate Negative Correlations:**\n",
        "- Entertainment ratings have a moderate negative correlation with ground service ratings."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Pair Plot**"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a scatterplot matrix using Seaborn\n",
        "sns.set(style='ticks')\n",
        "sns.pairplot(airline_df[variables])\n",
        "\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot is a data visualization tool that creates a grid of scatter plots to explore the pairwise relationships between multiple variables in a dataset. It's especially helpful for identifying correlations, patterns, and trends among variables. This can inform decisions in app development and marketing."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of passenger ratings, overall satisfaction shows a positive correlation with all other ratings. This means that passengers who rate specific categories highly tend to also give higher overall ratings.\n",
        "\n",
        "The strongest positive correlation exists between overall satisfaction and \"value for money\" (0.906), followed by \"ground service\" (0.846) and \"cabin service\" (0.795).\n",
        "\n",
        "There's a moderate positive correlation (0.733) between \"seat comfort\" and \"cabin service,\" indicating that passengers who rate seat comfort highly also tend to rate cabin service highly.\n",
        "\n",
        "\"Ground service\" and \"value for money\" have a positive correlation (0.796), suggesting that passengers who experience better ground services also tend to rate the airline's value for money more positively.\n",
        "\n",
        "\"Food and beverage\" and \"entertainment\" are positively correlated (0.610), implying that passengers who appreciate the quality of food and beverage also tend to rate the entertainment options higher.\n",
        "\n",
        "The correlation between \"entertainment\" and \"ground service\" is weaker (0.470), indicating a milder relationship. Passengers who find entertainment satisfying may also perceive better ground services.\n",
        "\n",
        "\"Value for money\" and \"overall\" have a strong positive correlation (0.906), suggesting that passengers who believe they are receiving good value for their money are more likely to give higher overall satisfaction ratings."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis Statement 1:**\n",
        "The distribution of ratings for food and beverage features at levels 2, 4, and 5 is approximately equal.\n",
        "\n",
        "**Hypothesis Statement 2:**\n",
        "On average, passengers in Business Class rate cabin service higher than passengers in Economy class.\n",
        "\n",
        "**Hypothesis Statement 3:**\n",
        "Passengers traveling for solo leisure purposes tend to give higher average ratings for seat comfort compared to passengers traveling for business purposes."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The food and beverage feature ratings of 2, 4, and 5 are not equally distributed, indicating that their frequencies are approximately equal.\n",
        "\n",
        "Alternative Hypothesis (H1): The food and beverage feature ratings of 2, 4, and 5 are equally distributed, indicating that their frequencies are not approximately equal.\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothesis: Food and beverage ratings 2, 4, and 5 are equally distributed.\n",
        "\n",
        "# Select the relevant data for food and beverage ratings 2, 4, and 5\n",
        "food_bev_ratings = airline_df[airline_df['food_bev'].isin([2, 4, 5])]['food_bev']\n",
        "\n",
        "# Calculate the observed frequencies of each rating\n",
        "observed_freq = food_bev_ratings.value_counts()\n",
        "\n",
        "# Calculate the expected frequency assuming an equal chance for each rating\n",
        "expected_freq = len(food_bev_ratings) / 3\n",
        "\n",
        "# Perform a chi-square test to determine if the observed and expected frequencies are significantly different\n",
        "chi2_stat, p_value = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Print the results of the hypothesis test\n",
        "print(\"\\nHypothesis 1:\")\n",
        "print(\"------\"*5)\n",
        "print(f\"Chi-square statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, a chi-square test is executed to calculate the p-value, assessing the statistical significance of the association between categorical variables. Specifically, it tests whether the observed frequencies of food and beverage ratings 2, 4, and 5 differ significantly from the expected frequencies, assuming an equal probability for each rating."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected the chi-square test for Hypothesis 1, which aims to examine whether food and beverage ratings 2, 4, and 5 are equally distributed. This test is suitable for analyzing categorical data and determining if observed frequencies significantly differ from expected frequencies. In our case, we're assessing the distribution of these ratings to see if there's any statistically significant deviation from the expected distribution."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): Passengers who travel in Business Class do not rate cabin service equally on average compared to passengers who travel in Economy class.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who travel in Business Class rate cabin service higher on average compared to passengers who travel in Economy class."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothesis 2: Business Class passengers rate cabin service higher than Economy Class passengers.\n",
        "\n",
        "# Select ratings for Business Class passengers\n",
        "business_class_ratings = airline_df[airline_df['cabin'] == 'Business Class']['cabin_service']\n",
        "\n",
        "# Select ratings for Economy Class passengers\n",
        "economy_class_ratings = airline_df[airline_df['cabin'] == 'Economy Class']['cabin_service']\n",
        "\n",
        "# Perform an independent two-sample t-test with unequal variances assumed\n",
        "t_stat, p_value = stats.ttest_ind(business_class_ratings, economy_class_ratings, equal_var=False)\n",
        "\n",
        "# Print the results of the hypothesis test\n",
        "print(\"\\nHypothesis 2:\")\n",
        "print('---'*10)\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we perform an independent two-sample t-test to calculate the p-value for Hypothesis 2. This test helps us assess if there is a statistically significant difference between the means of two independent groups. Specifically, we use the t-test to compare the average cabin service ratings of passengers in Business Class and Economy Class."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Hypothesis 2, which compares cabin service ratings between Business Class and Economy Class passengers, we opted for the independent two-sample t-test for the following reasons:\n",
        "\n",
        "1. Data Type: The cabin service ratings are numeric and continuous, making the t-test an appropriate choice.\n",
        "\n",
        "2. Two-Group Comparison: The hypothesis involves comparing the means of two distinct groups (Business Class and Economy Class passengers).\n",
        "\n",
        "3. Normality Assumption: Although the t-test assumes normal distribution within each group, for larger sample sizes, it can still provide valid results even if this assumption is not entirely met."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): Passengers who travel for Solo Leisure do not rate seat comfort equally on average compared to passengers who travel for Business purposes.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who travel for Solo Leisure tend to rate seat comfort higher on average compared to passengers who travel for Business purposes."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothesis 3: Solo Leisure travelers rate seat comfort higher than Business travelers.\n",
        "\n",
        "# Select ratings for Solo Leisure travelers\n",
        "solo_leisure_ratings = airline_df[airline_df['traveller_type'] == 'Solo Leisure']['seat_comfort']\n",
        "\n",
        "# Select ratings for Business travelers\n",
        "business_travel_ratings = airline_df[airline_df['traveller_type'] == 'Business']['seat_comfort']\n",
        "\n",
        "# Perform an independent two-sample t-test with unequal variances assumed\n",
        "t_stat, p_value = stats.ttest_ind(solo_leisure_ratings, business_travel_ratings, equal_var=False)\n",
        "\n",
        "# Print the results of the hypothesis test\n",
        "print(\"\\nHypothesis 3:\")\n",
        "print(\"---\"*10)\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Hypothesis 3 within the provided code, we employ an independent two-sample t-test, also known as Welch's t-test, to calculate the p-value. This test is implemented using the stats.ttest_ind() function from the SciPy library.\n",
        "\n",
        "The independent two-sample t-test is chosen when comparing the means of two groups, particularly when the assumption of equal variances is not met. In this instance, we use the equal_var=False argument with the stats.ttest_ind() function, signifying that we do not assume equal variances between the two groups."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose the independent two-sample t-test for Hypothesis 3 due to the following reasons:\n",
        "\n",
        "1. Data Type: Our data involves two independent groups, Solo Leisure travelers and Business travelers, and we want to compare the means of a continuous variable, seat comfort ratings, between them.\n",
        "\n",
        "2. Sample Size and Normality: The t-test is suitable when sample sizes are relatively large (usually over 30) and the data distribution is approximately normal. Even with moderate deviations from normality, t-tests can still yield valid results when sample sizes are very large and distributions are not highly skewed.\n",
        "\n",
        "3. Assumption of Equal Variances: The assumption of equal variances between the two groups is not met in our case. Therefore, we use Welch's t-test, which doesn't assume equal variances and is robust when variances differ between groups."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical columns in the dataframe\n",
        "numerical_cols = airline_df.select_dtypes(include='number').columns\n",
        "\n",
        "# Set the z-score threshold for identifying outliers\n",
        "z_score_threshold = 3\n",
        "\n",
        "# Dictionary to store the percentage of outliers for each numerical column\n",
        "percentage_of_outliers = {}\n",
        "\n",
        "# Loop through each numerical column and calculate the percentage of outliers\n",
        "for col in numerical_cols:\n",
        "    # Calculate the mean and standard deviation for the current column\n",
        "    col_mean = airline_df[col].mean()\n",
        "    col_std = airline_df[col].std()\n",
        "\n",
        "    # Calculate the z-scores for all values in the column\n",
        "    z_scores = np.abs((airline_df[col] - col_mean) / col_std)\n",
        "\n",
        "    # Count the number of outliers based on the z-score threshold\n",
        "    num_outliers = len(airline_df[z_scores > z_score_threshold])\n",
        "\n",
        "    # Calculate the percentage of outliers for the current column\n",
        "    percentage = (num_outliers / len(airline_df)) * 100\n",
        "\n",
        "    # Store the percentage of outliers in the dictionary\n",
        "    percentage_of_outliers[col] = percentage\n",
        "\n",
        "# Print the percentage of outliers for each numerical column\n",
        "for col, percentage in percentage_of_outliers.items():\n",
        "    print(f\"Percentage of outliers in {col}: {percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I did not apply any outlier removal techniques to our dataset because there were no outliers present."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the categorical columns in the DataFrame\n",
        "categorical_columns = airline_df.select_dtypes(include=[\"object\"]).columns.unique()\n",
        "\n",
        "# Print the categorical columns\n",
        "print(\"Categorical Columns:\")\n",
        "for col in categorical_columns:\n",
        "    print(col)\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will process the 'customer_review' feature as textual data. The 'author,' 'arrival_city,' and 'departure_city' features are not significant for our machine learning model, and we plan to drop them during feature manipulation."
      ],
      "metadata": {
        "id": "05Y0nn-RS0ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the categorical columns to be encoded\n",
        "categorical_columns = [\"airline\", \"traveller_type\", \"cabin\", \"recommended\"]\n",
        "\n",
        "# Create a label encoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the label encoder for each categorical column\n",
        "for column in categorical_columns:\n",
        "    airline_df[column] = le.fit_transform(airline_df[column])\n",
        "\n",
        "# Print the encoded dataset\n",
        "print(\"Encoded Dataset:\")\n",
        "print(airline_df)\n"
      ],
      "metadata": {
        "id": "eG19RX2bS8qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We employ label encoding for categorical columns since many machine learning algorithms exclusively work with numerical data. Label encoding assigns a unique integer to each category, enabling algorithms to comprehend the relationships between categories.\n",
        "\n",
        "Advantages of label encoding include simplicity, efficiency, and compatibility with a wide range of machine learning algorithms."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a 'customer_review' feature containing textual data in our dataset. To utilize this data in feature selection, we will convert the text reviews into numeric representations using Natural Language Processing (NLP). This will help us identify which reviews are providing recommendations."
      ],
      "metadata": {
        "id": "qqD3_iRyTmM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the vaderSentiment package using pip\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "c2-lqJzFTwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the SentimentIntensityAnalyzer class from the vaderSentiment package\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
      ],
      "metadata": {
        "id": "mW1AnOXjT3ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the SentimentIntensityAnalyzer class from the vaderSentiment package\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Create a function to get the sentiment score for a given sentence\n",
        "def sentiment_scores(sentence):\n",
        "    # Create a SentimentIntensityAnalyzer object\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Calculate the sentiment scores for the sentence\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "    # Return the compound sentiment score\n",
        "    return sentiment_dict['compound']\n",
        "\n",
        "# Create a new column 'numeric_review' to store sentiment polarity for each customer review\n",
        "# Apply the 'sentiment_scores' function to each customer review in the 'customer_review' column\n",
        "airline_df['numeric_review'] = airline_df['customer_review'].apply(sentiment_scores)\n",
        "\n",
        "\n",
        "# Display the first 10 rows of the DataFrame, showing 'customer_review' and 'numeric_review' columns\n",
        "print(airline_df[['customer_review', 'numeric_review']].head(10))\n"
      ],
      "metadata": {
        "id": "9EWBRm9pT9Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns that are not needed for analysis\n",
        "# This can help minimize feature correlation and simplify the dataset\n",
        "columns_to_drop = ['author', 'review_date', 'date_flown', 'customer_review', 'month', 'flight_year', 'flight_month', 'arrival_city', 'departure_city']\n",
        "airline_df = airline_df.drop(columns_to_drop, axis=1)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the feature matrix 'X' and the target variable 'y'\n",
        "X = airline_df.drop(columns=['recommended'])  # Feature matrix\n",
        "y = airline_df['recommended']  # Target variable\n",
        "\n",
        "# Number of top features to select\n",
        "k = 11\n",
        "\n",
        "# Perform feature selection using ANOVA F-tests\n",
        "# SelectKBest is used to select the top k features based on their F-scores\n",
        "selector = SelectKBest(score_func=f_regression, k=k)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the names and scores of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "selected_feature_scores = selector.scores_[selected_feature_indices]\n",
        "\n",
        "# Now, 'X_selected' contains only the selected features, and 'selected_feature_names' contains their names.\n",
        "# Print the selected features and their corresponding ANOVA F-values\n",
        "print(\"Selected Features:\")\n",
        "for feature, score in zip(selected_feature_names, selected_feature_scores):\n",
        "    print(f\"{feature}: ANOVA F-value = {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code for feature selection in the merged dataset, we utilized the SelectKBest method with the ANOVA (Analysis of Variance) score function. Here's why:\n",
        "\n",
        "SelectKBest with ANOVA: SelectKBest is a scikit-learn feature selection technique that selects the best 'k' features based on statistical tests. The ANOVA score function is employed for regression tasks, assessing the relationship between each feature and the continuous target variable.\n",
        "\n",
        "Reason for Choice: We opted for this method because our target variable, 'Sales,' is continuous in a regression task. ANOVA F-values help us gauge the significance of each feature's relationship with the target. By selecting the top 'k' features, we aim to retain the most informative ones while reducing model complexity and potential overfitting."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. airline: Influences passenger experience due to varying service levels.\n",
        "2. overall: Direct measure of passenger satisfaction, a critical indicator.\n",
        "3. traveller_type: Different traveler types may have distinct preferences.\n",
        "4. seat_comfort: Crucial for comfort during air travel.\n",
        "5. cabin_service: Impacts passenger satisfaction, including in-flight service.\n",
        "6. food_bev: Quality of food and beverages affects comfort.\n",
        "7. entertainment: Enhances the overall travel experience.\n",
        "8. ground_service: Shapes perception through check-in, boarding, etc.\n",
        "9. value_for_money: Reflects passenger's perceived worth of expenses.\n",
        "10. numeric_review: May capture additional insights from customer review text."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# Use a 80-20 split ratio, with 80% of the data for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "# Print the shapes of the training and testing sets to verify the split\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test_size parameter in train_test_split determines the proportion of data allocated to the testing set when splitting the dataset. In this code, test_size=0.2 is used, meaning 20% of the data is allocated to testing, leaving 80% for training. Commonly used ratios are 80:20 (test_size=0.2) and 70:30 (test_size=0.3) to balance training data and reliable testing evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the column names for the evaluation metrics DataFrame\n",
        "column_names = [\"MODEL NAME\", \"ACCURACY\", \"RECALL\", \"PRECISION\", \"F1-SCORE\", \"ROC AUC SCORE\"]\n",
        "\n",
        "# Create an empty DataFrame with the specified column names\n",
        "evaluation_results = pd.DataFrame(columns=column_names)\n",
        "\n",
        "# We can now populate this DataFrame with evaluation metrics for different models."
      ],
      "metadata": {
        "id": "QsaexBb-ZIEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to add evaluation metrics for a model to a DataFrame\n",
        "def add_metrics_details(model_name, y_test, y_pred, df):\n",
        "    # Append a new row to the DataFrame with metrics for the model\n",
        "    df = df.append({\n",
        "        'MODEL NAME': model_name,\n",
        "        'ACCURACY': accuracy_score(y_test, y_pred),\n",
        "        'RECALL': recall_score(y_test, y_pred),\n",
        "        'PRECISION': precision_score(y_test, y_pred),\n",
        "        'F1-SCORE': f1_score(y_test, y_pred),\n",
        "        'ROC AUC SCORE': roc_auc_score(y_test, y_pred)\n",
        "    }, ignore_index=True)\n",
        "\n",
        "    # Return the updated DataFrame\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "FSrufLU3ZY2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "log_reg = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "\n",
        "# Fit the Logistic Regression model on the training data\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained model on the test data\n",
        "y_pred_logreg = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the Logistic Regression model\n",
        "score = log_reg.score(X_test, y_test)\n",
        "print(f'Logistic regression score: {score}')\n",
        "\n",
        "# Create a DataFrame to compare actual and predicted values\n",
        "data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_logreg})\n",
        "\n",
        "# Print the DataFrame to display actual and predicted values\n",
        "print(\"Comparison of Actual and Predicted Values:\")\n",
        "print(data)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Calculate and print the accuracy score of the model\n",
        "accuracy = accuracy_score(y_test, y_pred_logreg)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_logreg, labels=[1, 0])\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "sns.heatmap(cm, annot=True, fmt=\".1f\", cmap='icefire')\n",
        "plt.title('Confusion Matrix for Logistic Regression')\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the Logistic Regression model to metrics_df\n",
        "evaluation_results = add_metrics_details(\"Logistic Regression\", y_test, y_pred_logreg, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "Kr8h-kaBaEfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (RandomizedSearchCV)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "scores = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\", scores.min(), scores.max())\n",
        "\n",
        "# Define hyperparameters distribution\n",
        "param_dist = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "logreg_hyper = RandomizedSearchCV(log_reg, param_distributions=param_dist, n_iter=10, cv=10)\n",
        "\n",
        "# Fit the Logistic Regression model with hyperparameter optimization\n",
        "logreg_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = logreg_hyper.best_params_\n",
        "best_score = logreg_hyper.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Predict on the model with optimized hyperparameters\n",
        "y_pred_logreg_hyper = logreg_hyper.predict(X_test)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart for the model with optimized hyperparameters\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_logreg_hyper))\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_logreg_hyper, labels=[1, 0])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the accuracy score of the model\n",
        "accuracy = accuracy_score(y_test, y_pred_logreg_hyper)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n"
      ],
      "metadata": {
        "id": "RO9YSzJYah-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the Logistic Regression model with tuning to metrics_df\n",
        "evaluation_results = add_metrics_details(\"Logistic Regression With Tuning\", y_test, y_pred_logreg_hyper, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "-oemyODOaptt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Faster Computation: RandomizedSearchCV is faster than GridSearchCV because it evaluates fewer hyperparameter combinations randomly.\n",
        "\n",
        "2. Flexibility: It allows specifying the number of iterations, making it more flexible for exploring a large hyperparameter space.\n",
        "\n",
        "3. Better Exploration: RandomizedSearchCV explores a broader range of hyperparameters, which can be advantageous when the best values are not on the grid points.\n",
        "\n",
        "4. Resource-Efficient: It is more resource-efficient for computationally expensive models and large datasets due to fewer iterations compared to GridSearchCV."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After hyperparameter tuning, we observed slight improvements in most metrics:\n",
        "\n",
        "- Accuracy increased slightly.\n",
        "- Recall remained unchanged.\n",
        "- Precision showed a slight improvement.\n",
        "- F1-Score increased slightly.\n",
        "- ROC AUC Score also improved marginally.\n",
        "\n",
        "Overall, these improvements, while consistent, are modest. It seems hyperparameter tuning fine-tuned the model's performance, but the gains might not outweigh the computational cost involved."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbour - ML Model"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model Implementation (K-Nearest Neighbors)\n",
        "\n",
        "# Number of neighbors (k) for KNN\n",
        "k = 5\n",
        "\n",
        "# Create a KNeighborsClassifier with k neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Fit the KNN model on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained KNN model on the test data\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the KNN model\n",
        "score = knn.score(X_test, y_test)\n",
        "print(f'K-Nearest Neighbors score : {score}')\n",
        "\n",
        "# Create a DataFrame to compare actual and predicted values\n",
        "data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_knn})\n",
        "\n",
        "# Print the DataFrame to display actual and predicted values\n",
        "print(\"Comparison of Actual and Predicted Values for KNN:\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "sqoWMR0kkVUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart for the KNN model\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_knn, labels=[1, 0])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the accuracy score of the KNN model\n",
        "accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "sns.heatmap(cm, annot=True, fmt=\".1f\", cmap='icefire')\n",
        "plt.title('Confusion Matrix for K-Nearest Neighbors')\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the K-Nearest Neighbors (KNN) model to metrics_df\n",
        "evaluation_results = add_metrics_details(\"K-Nearest Neighbours\", y_test, y_pred_knn, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "mnPqDGqFklXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\", scores.max(), scores.min())\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_neighbors': np.arange(1, 9),  # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Weighting method\n",
        "    'p': [1, 2]  # Distance metric (1: Manhattan, 2: Euclidean)\n",
        "}\n",
        "\n",
        "# Create GridSearchCV with 5-fold cross-validation\n",
        "knn_hyper = GridSearchCV(knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the KNN model with hyperparameter tuning\n",
        "knn_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = knn_hyper.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", knn_hyper.best_params_)\n",
        "print(\"Best Score:\", knn_hyper.best_score_)\n",
        "\n",
        "# Predict on the test data using the best model\n",
        "y_pred_knn_hyper = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart for the KNN model with hyperparameter tuning\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_knn_hyper))\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_knn_hyper, labels=[1, 0])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the accuracy score of the KNN model with hyperparameter tuning\n",
        "accuracy = accuracy_score(y_test, y_pred_knn_hyper)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n"
      ],
      "metadata": {
        "id": "4UFuSxAwlFfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the K-Nearest Neighbors (KNN) model with tuning to metrics_df\n",
        "evaluation_results = add_metrics_details(\"K-Nearest Neighbours With Tuning\", y_test, y_pred_knn_hyper, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "uZbwKa-7lG-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, GridSearchCV was employed for hyperparameter optimization with the following benefits:\n",
        "\n",
        "1. Exhaustive Search: GridSearchCV systematically explores all possible hyperparameter combinations, leaving no potential improvement unchecked.\n",
        "\n",
        "2. Cross-Validation: It uses 5-fold cross-validation to estimate model performance on unseen data, enhancing reliability.\n",
        "\n",
        "3. Best Parameters and Score: GridSearchCV identifies the best hyperparameter combination and provides the corresponding score, aiding in optimal parameter selection.\n",
        "\n",
        "4. Automated Tuning: GridSearchCV automates the time-consuming process of hyperparameter tuning, saving effort.\n",
        "\n",
        "5. Generalization: Through cross-validation, it ensures that chosen hyperparameters generalize well to new data."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After comparing the results, it appears that there's not a significant difference in performance between the K-Nearest Neighbors model and the tuned version. The metrics show minimal variation:\n",
        "\n",
        "- Accuracy is slightly lower after tuning.\n",
        "- Recall remains similar.\n",
        "- Precision improves slightly.\n",
        "- F1-Score remains relatively consistent.\n",
        "- ROC AUC Score is similar.\n",
        "\n",
        "Hyperparameter tuning in this case hasn't led to significant improvements. It's possible that the default hyperparameters were already well-suited for this dataset, highlighting the importance of not blindly applying tuning, as default settings can sometimes be effective."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine - ML Model"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) Implementation\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Fit the SVM model on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained SVM model on the test data\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the SVM model\n",
        "score = svm.score(X_test, y_test)\n",
        "print(f'Support Vector Machine Score : {score}')\n",
        "\n",
        "# Create a DataFrame to compare actual and predicted values\n",
        "data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_svm})\n",
        "\n",
        "# Print the DataFrame to display actual and predicted values\n",
        "print(\"Comparison of Actual and Predicted Values for SVM:\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart for the SVM model\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_svm, labels=[1, 0])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the accuracy score of the SVM model\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "sns.heatmap(cm, annot=True, fmt=\".1f\", cmap='icefire')\n",
        "plt.title('Confusion Matrix for Support Vector Machine')\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the Support Vector Machine (SVM) model to metrics_df\n",
        "evaluation_results = add_metrics_details(\"Support Vector Machine\", y_test, y_pred_svm, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "-UsJLLLtmruT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 5-fold cross-validation for the SVM model\n",
        "scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\", scores.max(), scores.min())\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "   'kernel': ['rbf'],\n",
        "    'C': [10],\n",
        "    'gamma': ['scale']\n",
        "}\n",
        "\n",
        "# Create GridSearchCV with 5-fold cross-validation\n",
        "svm_hyper = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the SVM model with hyperparameter tuning\n",
        "svm_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = svm_hyper.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", svm_hyper.best_params_)\n",
        "print(\"Best Score:\", svm_hyper.best_score_)\n",
        "\n",
        "# Predict on the test data using the best model with optimized hyperparameters\n",
        "y_pred_svm_hyper = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation metric score chart for the SVM model with hyperparameter tuning\n",
        "\n",
        "# Print the classification report\n",
        "print(metrics.classification_report(y_test, y_pred_svm_hyper))\n",
        "\n",
        "# Create a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_svm_hyper, labels=[1, 0])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate and print the accuracy score of the SVM model with hyperparameter tuning\n",
        "accuracy = accuracy_score(y_test, y_pred_svm_hyper)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy * 100, 2)}%\\n')\n"
      ],
      "metadata": {
        "id": "XA20EgAcm-Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add evaluation metrics for the Support Vector Machine (SVM) model with tuning to metrics_df\n",
        "evaluation_results = add_metrics_details(\"Support Vector Machine With Tuning\", y_test, y_pred_svm_hyper, evaluation_results)\n",
        "\n",
        "# Print the updated metrics_df\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "SkdIzn2XnDC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I employed GridSearchCV in the SVM model for hyperparameter optimization due to the following advantages:\n",
        "\n",
        "1. Exhaustive Search: GridSearchCV thoroughly explores all hyperparameter combinations, ensuring no potential optimal configuration is overlooked.\n",
        "\n",
        "2. Tuning Multiple Hyperparameters: SVM models have multiple hyperparameters, and GridSearchCV allows concurrent tuning of these parameters.\n",
        "\n",
        "3. Cross-Validation: The method performs cross-validation to ensure selected hyperparameters generalize well to unseen data, mitigating overfitting.\n",
        "\n",
        "4. Best Model Selection: GridSearchCV provides the best hyperparameter combination and its corresponding model, facilitating straightforward model selection.\n",
        "\n",
        "5. Custom Scoring Metric: It allows optimization based on a user-defined scoring metric, enhancing flexibility in model performance evaluation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After comparing the results, it appears that there's not a substantial difference in performance between the SVM model and the tuned version. The metrics show minimal variation:\n",
        "\n",
        "- Accuracy slightly decreases after tuning.\n",
        "- Recall remains similar.\n",
        "- Precision improves slightly.\n",
        "- F1-Score remains consistent.\n",
        "- ROC AUC Score is also similar.\n",
        "\n",
        "Hyperparameter tuning hasn't resulted in significant performance improvements for the SVM model. This suggests that the default hyperparameters may have already been well-suited for this dataset, emphasizing the importance of assessing the impact of tuning on specific models and datasets."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've provided a clear and concise explanation of the key evaluation metrics for assessing positive business impactprecision, recall, and ROC AUC scoreand their respective importance in different contexts. These metrics play a critical role in determining the effectiveness of a model in real-world applications, depending on the relative costs and consequences of false positives and false negatives. Striking a balance between precision and recall is often crucial for optimizing business outcomes."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the evaluation metrics for all models in the metrics_df DataFrame\n",
        "print(\"Evaluation Metrics for All Models:\")\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "mkn7euf8pIf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the provided evaluation metrics dataframe, it appears that the Support Vector Machine (SVM) without hyperparameter tuning is performing well in terms of accuracy, recall, precision, and ROC AUC score. Here's a summary of its performance:\n",
        "\n",
        "- **Accuracy:** The accuracy score indicates the overall correctness of the model's predictions, and the SVM without tuning has a high accuracy score.\n",
        "\n",
        "- **Recall:** Recall, also known as sensitivity or true positive rate, measures the model's ability to correctly identify positive instances. The SVM without tuning has a good recall score, indicating that it effectively identifies positive cases.\n",
        "\n",
        "- **Precision:** Precision measures the model's ability to make positive predictions correctly. The SVM without tuning has a reasonable precision score, suggesting that it maintains a good balance between correctly identifying positive cases and minimizing false positives.\n",
        "\n",
        "- **ROC AUC Score:** The ROC AUC score reflects the model's ability to distinguish between positive and negative instances. The SVM without tuning has a high ROC AUC score, indicating strong discriminative power.\n",
        "\n",
        "In summary, the SVM without hyperparameter tuning appears to provide a good trade-off between accuracy, recall, precision, and ROC AUC score, suggesting that it's performing well in identifying positive instances while maintaining overall prediction quality. However, it's important to consider other factors such as model complexity and computational resources when choosing a model for deployment in practice."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming svm_model is your trained SVM model\n",
        "svm_model = SVC(C=1, kernel='linear', probability=True)  # Example parameters, replace with your tuned parameters\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the coefficients of the support vector machine model\n",
        "coef = svm_model.coef_[0]\n",
        "\n",
        "# Get the feature names from your feature dataframe\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame to display the coefficients and their corresponding features\n",
        "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coef})\n",
        "\n",
        "# Sort the DataFrame by coefficient magnitude (absolute value)\n",
        "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
        "\n",
        "# Plot the coefficients using Matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(coef_df['Feature'], coef_df['Coefficient'], color='skyblue')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Feature Importance - SVM Coefficients')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iQ6k7Gg9peby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis (EDA) Insights:**\n",
        "- Traveller Types and Cabin Class: Business travelers tend to rate cabin service higher than other traveler types, and Business Class passengers rate cabin service higher than Economy Class passengers.\n",
        "- Seat Comfort and Travel Purpose: Solo Leisure travelers tend to rate seat comfort higher compared to Business travelers.\n",
        "- Food and Beverage Ratings: Ratings of 2, 4, and 5 are equally distributed for food and beverage, indicating a balanced distribution.\n",
        "\n",
        "**Machine Learning Models Evaluated:**\n",
        "- Logistic Regression: Achieved an initial accuracy of 96%.\n",
        "- K-Nearest Neighbours: Performed well with an accuracy of 95.97%, slightly decreased to 95.92% after hyperparameter tuning.\n",
        "- Support Vector Machine (SVM): Emerged as a strong contender with an accuracy of 96.57%.\n",
        "\n",
        "**Feature Importance:**\n",
        "- Key attributes like seat comfort, cabin service, and overall ratings consistently influenced model predictions, albeit to varying degrees.\n",
        "\n",
        "**Final Model Selection:**\n",
        "- Chose the Support Vector Machine (SVM) model with hyperparameter tuning as the final prediction model due to its remarkable 96.57% accuracy.\n",
        "- SVM's ability to handle complex relationships and non-linear decision boundaries made it the optimal choice.\n",
        "\n",
        "**Feature Importance Analysis:**\n",
        "- Explored feature importance through coefficient analysis, providing insights into attribute contributions.\n",
        "- Acknowledged that SVM models may not offer straightforward feature importance interpretation due to their decision boundary nature.\n",
        "\n",
        "**Conclusion:**\n",
        "- Project journey encompassed data exploration, model construction, and evaluation, resulting in a reliable airline passenger referral prediction model.\n",
        "- Insights gained can guide the airline industry in understanding passenger preferences and enhancing services for improved customer satisfaction and referrals."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}